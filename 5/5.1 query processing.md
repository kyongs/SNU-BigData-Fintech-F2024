## 5.1 query processing

- LiveSQL worksheet에서 가급적 SQL문 한개씩 실행해보세요. (SQL문은 ;(세미콜론)으로 끝납니다. )
- 해당 예시에서는 scott.sql을 미리 실행하지 않으셔도 됩니다.
- 실행 쿼리 종류에 따라 테이블에 데이터가 완전히 반영되기까지 시간이 걸릴수도 있습니다. 그런 경우, 쿼리를 재실행해주세요.
- LiveSQL 공간이 모자를때는 아래 sql문을 재실행해주세요.

  ```sql
  drop table TEST;

  create table TEST (a int, b int, c varchar2(650));

  -- Insert 1,000,000 tuples into test table
  BEGIN
      FOR i IN 1..10 LOOP
          FOR j IN 1..100 LOOP
              INSERT INTO TEST (a, b, c) values ((i-1)*10000+j, j, rpad('X', 650, 'X'));
      END LOOP;
      END LOOP;
  END;
  ```

<br/><br/>

### [실습]

```sql
--===================================
--  Create and Populate TEST TABLE --
--===================================
drop table test;
create table test (a int, b int, c varchar2(650));

BEGIN
    FOR i IN 1..10 LOOP
        FOR j IN 1..10000 LOOP
            INSERT INTO TEST (a, b, c) values ((i-1)*10000+j, j, rpad('X', 650, 'X'));
        END LOOP;
    END LOOP;
END;

select table_name, tablespace_name, blocks, pct_free, avg_row_len, avg_space
from user_tables
where table_name = 'TEST';

-- create test_idx_a, test_idx_b and analyze
create index test_idx_a on test(a);
create index test_idx_b on test(b);

-- create index test_idx_ab on test(a,b);
analyze index test_idx_a compute statistics;
analyze index test_idx_b compute statistics;

select index_name, blevel, leaf_blocks, distinct_keys, avg_leaf_blocks_per_key, avg_data_blocks_per_key, clustering_factor, last_analyzed
from user_indexes
where index_name in ('TEST_IDX_A', 'TEST_IDX_B');

```

### 14.4 Join

```sql
--=============
-- 14.4 Join --
--=============
alter session set optimizer_features_enable = '9.2.0'

--===============================
-- create/populate SMALL TABLE --
--===============================

drop table SMALL;
create table SMALL (a int, b int, c varchar2(650));
BEGIN
    FOR i IN 1..1000 LOOP
            INSERT INTO SMALL (a, b, c) values (i, i, rpad('X', 650, 'X'));
    END LOOP;
END;

-- 10 tuples/block, 1000 blocks, total = 8MB
analyze table small compute statistics;
select table_name, tablespace_name, blocks, pct_free, avg_row_len, avg_space
from user_tables
where table_name = 'SMALL';

create index small_idx_a on small(a);
analyze index small_idx_a compute statistics;

select index_name, blevel, leaf_blocks, distinct_keys, avg_leaf_blocks_per_key, avg_data_blocks_per_key, clustering_factor, last_analyzed
from user_indexes
where index_name = 'SMALL_IDX_A';

--==================
-- JOIN: examples --
--==================

-- A quick review of join
select ename, dname
from scott.emp e, scott.dept d
where e.deptno = d.deptno

-- -- nested loop algorithm
select * from scott.emp;
select * from scott.dept;

-- -- sort merge algorithm
select * from scott.emp order by deptno;
select * from scott.dept order by deptno;

-- hash algorithm : a very simple hash function mod(deptno, 17)
select ename, deptno, mod(deptno, 17) from scott.emp;
select deptno, mod(deptno, 17), dname from scott.dept;

--======================
-- Simple Nested Loop ==
--======================
select /*+ use_nl(t1, t2) full(t1) full(t2) */ sum(t1.b + t2.b)
from test t1, small t2
where t1.a = t2.a;

select /*+ use_nl(t1, t2) full(t1) full(t2) */ sum(t1.b + t2.b)
from test t1, small t2
where t1.a = t2.a and t1.a between 1 and 1000;

--==========================
-- JOIN ORDER IMPORTANT!! ==
--==========================
-- the hint "ordered" enforce the optimizer to consider only
-- the join order (t2, t1).
select /*+ ordered use_nl(t1, t2) full(t1) full(t2) */ sum(t1.b + t2.b)
from small t2, test t1
where t1.a = t2.a;

--=======================
-- Indexed Nested Loop ==
--=======================
select /*+ ordered use_nl(t1, t2) full(t1) */ sum(t1.b + t2.b)
from test t1, small t2
where t1.a = t2.a;

select /*+ use_nl(t1, t2) full(t2) */ sum(t1.b + t2.b)
from test t1, small t2
where t1.a = t2.a;

select /*+ ordered use_nl(t1, t2) full(t1) */ sum(t1.b + t2.b)
from small t1, test t2
where t1.a = t2.a;

--===========================
-- SORT-MERGE & HASH JOIN  ==
--===========================

select /*+ use_merge(t1, t2) */ sum(t1.a + t2.a)
from test t1, small t2
where t1.b = t2.b;
-- SORT (JOIN)

select /*+ use_hash(t1, t2) */ sum(t1.a + t2.a)
from test t1, small t2
where t1.b = t2.b;
-- HASH JOIN

-- SORT-MERGE and HASH JOIN COST MODEL: Too Complex!!
-- Excuse me for not providing EXACT information!!

-- Without any hint, which plan does Oracle choose?
-- No hint on access method, join method, and join order
select sum(t1.a + t2.a)
from test t1, small t2
where t1.b = t2.b;

--=====================================
-- Join method for NON-EQUALITY JOIN ==
--=====================================

select sum(t1.b + t2.b)
from test t1, small t2
where t1.a <= t2.a and t1.a between 1 and 1000 and t2.a between 1 and 100;
-- hash can not support "<", ">" etc.

select /*+ use_hash(t1, t2) */ sum(t1.b + t2.b)
from test t1, small t2
where t1.a <= t2.a and t1.a between 1 and 1000 and t2.a between 1 and 100;
-- hash can not support "<", ">" etc.

select sum(t1.b + t2.b)
from test t1, small t2
where t1.a != t2.a and t1.a between 1 and 1000 and t2.a between 1 and 100;

select /*+ use_merge(t1,t2) */ sum(t1.b + t2.b)
from test t1, small t2
where t1.a != t2.a and t1.a between 1 and 1000 and t2.a between 1 and 100;
-- both sort_merge and hash can not support "!=".

```

### Chap 12. example.sql

```sql
drop table test;
create table test (a int, b int, c varchar2(650));

BEGIN
    FOR i IN 1..10 LOOP
        FOR j IN 1..100 LOOP
        	INSERT INTO TEST (a, b, c) values ((i-1)*1000+j, j, rpad('X', 650, 'X'));
	END LOOP;
    END LOOP;
END;
```

### 12.1 System Catalogs: Examples

```sql
-- analyze and check TEST and SMALL tables
analyze table TEST compute statistics;

-- table statistics: # of pages, # of tuples
select table_name, blocks, num_rows
from user_tables
where table_name in ('TEST', 'SMALL');

--================================================================
-- attribute statistics: # of distinct values, min/max, density --
-- NOTE: two assumptions in attribute statistics                --
-- 1. UNIFORM VALUE DISTRIBUTION                                --
-- 2. ATTRIBUTE VALUE INDEPENDENCE                              --
--================================================================
select table_name, column_name, data_type, num_distinct, low_value, high_value, density
from user_tab_columns
where table_name in ('TEST');

create index test_idx_a on test(a);
analyze index test_idx_a compute statistics;

-- index # of distinct keys, # of blocks, clustering factor, height (or level)
select table_name, index_name, blevel, leaf_blocks, distinct_keys, num_rows,
	clustering_factor, last_analyzed
from user_indexes
where table_name in ('TEST');

-- Column B is uniformly distributed. That is, B has no skew.
select * from test where b between 1 and 100;

-- NOTE: in reality, unlike the assumption 2 above,
-- value distributions of A and B columns are not independent
select * from test where a between 1 and 100 and b between 1 and 100;

--=============
-- Histogram --
--=============

-- skewed data distribution and histogram
drop table SKEWED;
create table SKEWED (a int, b int, c varchar2(650));

BEGIN
    FOR i IN 1..100 LOOP
        FOR j IN 1..i LOOP
        	insert into SKEWED (a, b, c) values (i, i, rpad('X', 650, 'X'));
	END LOOP;
    END LOOP;
END;
/

analyze table SKEWED compute statistics;
create index skewed_idx_a on skewed(a);
analyze index skewed_idx_a compute statistics;

select sum(b) from skewed where a between 91 and 100;
select sum(b) from skewed where a between 1 and 10;


```

Copyright SNU VLDB Lab. All Rights Reserved.
